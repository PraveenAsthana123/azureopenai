# ISO/IEC 42001 — AI Management System (Single Master Table)

> **Auditor-Ready | AI / GenAI / ML / RAG / Robotics**
>
> ISO/IEC 42001 ensures AI is trustworthy, compliant, and governable — while CMMI Level 3 ensures it is built and delivered consistently.

---

## What ISO 42001 Solves

| Problem Area | What ISO 42001 Enforces |
|--------------|-------------------------|
| Uncontrolled AI adoption | Formal AI governance & accountability |
| Regulatory exposure | Traceability, auditability, compliance-by-design |
| Ethical & trust risks | Bias, fairness, transparency controls |
| Security & privacy gaps | Data, model, and lifecycle safeguards |
| Shadow AI / GenAI sprawl | Inventory, approval, and monitoring |

---

## Master Control Table

| # | ISO 42001 Domain | Purpose (Why) | Standard Process (How) | Key Activities | Mandatory Artifacts / Evidence |
|---|------------------|---------------|------------------------|----------------|-------------------------------|
| 1 | **AI Context & Scope** | Define where AI is used and why | Identify AI use cases → Stakeholders → Risk context → Scope definition | AI inventory, stakeholder mapping, impact analysis | AI Scope Doc, AI Use-Case Register |
| 2 | **AI Leadership & Policy** | Establish accountability & direction | Define AI policy → Assign roles → Approve governance | Policy approval, role assignment | AI Policy, AI Governance Charter, RACI |
| 3 | **AI Risk Management** | Prevent harm & non-compliance | Identify → Assess → Mitigate → Monitor AI risks | Bias analysis, harm assessment, compliance checks | AI Risk Register, Mitigation Plans |
| 4 | **AI Use-Case Approval** | Control what AI is allowed | Intake → Risk classification → Approval | High-risk vs low-risk classification | AI Intake Form, Approval Records |
| 5 | **Data Governance for AI** | Ensure lawful & quality data | Data identification → Quality → Consent → Protection | Data lineage, bias checks, privacy controls | Data Inventory, Data Sheets, Consent Records |
| 6 | **Model & System Design Control** | Ensure responsible design | Design review → Explainability → Human oversight | Architecture review, XAI design | Model Cards, Architecture Docs |
| 7 | **Development & Change Control** | Prevent uncontrolled AI changes | Build → Test → Review → Approve → Deploy | Versioning, retraining approvals | Change Logs, Model Versions |
| 8 | **Verification & Validation** | Ensure AI behaves as intended | Test for accuracy, bias, robustness | Functional, ethical, performance testing | Test Plans, Bias Reports, Results |
| 9 | **Deployment & Operation** | Safe AI in production | Access control → Monitoring → Incident detection | Drift monitoring, output checks | Monitoring Logs, Alerts |
| 10 | **Human-in-the-Loop & Oversight** | Maintain human accountability | Define intervention points → Escalation | Manual review, override workflows | HITL SOP, Escalation Logs |
| 11 | **Incident & Non-Conformance Management** | Respond to AI failures | Detect → Report → Contain → Correct | Incident triage, root cause | Incident Reports, CAPA |
| 12 | **Supplier & Third-Party AI Management** | Control external AI risk | Assess vendors → Contract controls → Monitor | Due diligence, SLA checks | Vendor Risk Assessments |
| 13 | **Monitoring & Performance Evaluation** | Ensure ongoing compliance | KPI tracking → Internal audits → Reviews | Effectiveness metrics, audits | KPI Dashboard, Audit Reports |
| 14 | **Continual Improvement** | Improve AI governance over time | Lessons learned → Process updates → Training | Governance updates, retraining | Improvement Logs, Updated Policies |

---

## Core Structure (ISO Annex SL Alignment)

| Clause | Meaning (AI Context) |
|--------|----------------------|
| 4. Context of Organization | AI use-cases, stakeholders, risk appetite |
| 5. Leadership | AI policy, roles, accountability |
| 6. Planning | AI risk assessment & mitigation |
| 7. Support | Skills, data, documentation |
| 8. Operation | AI lifecycle controls |
| 9. Performance Evaluation | Monitoring, KPIs, audits |
| 10. Improvement | Incidents, corrective actions |

---

## Lifecycle Coverage

| Lifecycle Stage | Covered Controls |
|-----------------|------------------|
| Strategy & Use-Case Approval | Risk classification, impact assessment |
| Data Management | Quality, bias, provenance, privacy |
| Model Development | Design controls, explainability |
| Validation & Testing | Performance, robustness, bias testing |
| Deployment | Access control, change management |
| Operations (MLOps/LLMOps) | Monitoring, drift, incidents |
| Retirement | Decommissioning, knowledge retention |

---

## GenAI, LLM, and RAG Alignment

| GenAI Area | ISO 42001 Control |
|------------|-------------------|
| Prompt management | Change & access control |
| RAG pipelines | Data provenance & leakage prevention |
| Hallucination risk | Output monitoring & validation |
| Model updates | Versioning & rollback |
| Fine-tuning | Dataset risk assessment |
| API usage | Third-party AI risk |

---

## Mandatory AI Governance Artifacts

| Artifact | Purpose |
|----------|---------|
| AI Policy | Organizational intent & boundaries |
| AI Use-Case Inventory | Full visibility of all AI systems |
| AI Risk Assessment | Harm, bias, compliance analysis |
| Data Governance Register | Source, consent, sensitivity |
| Model Documentation | Explainability, assumptions |
| Human-in-the-Loop Design | Oversight & escalation |
| Incident Response Plan | AI failures & harm handling |

---

## ISO 42001 vs Other AI Standards

| Standard | Focus | Relation to ISO 42001 |
|----------|-------|----------------------|
| ISO 27001 | Information Security | Security foundation |
| ISO 27701 | Privacy | Privacy extension |
| ISO 23894 | AI Risk | Risk methodology input |
| EU AI Act | Regulation | Legal compliance mapping |
| NIST AI RMF | Risk framework | Complementary |

> **ISO 42001 is the umbrella governance system under which these align.**

---

## Certification Readiness Steps

| Phase | Key Actions |
|-------|-------------|
| Gap Assessment | Map current AI practices |
| Governance Design | Define AIMS structure |
| Control Implementation | Policies, workflows, tools |
| Evidence Collection | Logs, reports, metrics |
| Internal Audit | Readiness validation |
| Certification Audit | External audit |

---

## Auditor KPIs

| Dimension | Example KPI |
|-----------|-------------|
| Governance | % AI systems approved |
| Risk | High-risk AI mitigated |
| Data | % datasets with provenance |
| Explainability | Models with XAI |
| Incidents | Time to detect & resolve |
| Compliance | Audit findings closed |

---

## Priority Sectors for Adoption

- Healthcare & Life Sciences
- Banking & Insurance
- Government & Smart Cities
- Energy, Utilities & Oil & Gas
- Robotics & Autonomous Systems
- Enterprise GenAI Platforms

---

## Executive Summary

> **ISO/IEC 42001 ensures AI is trustworthy, compliant, and governable — while CMMI Level 3 ensures it is built and delivered consistently.**

---

## Document Control

| Field | Value |
|-------|-------|
| Version | 1.0 |
| Classification | Internal / Audit-Ready |
| Applicable To | AI, GenAI, ML, RAG, Robotics, LLM |
| Framework Reference | ISO/IEC 42001:2023 |
